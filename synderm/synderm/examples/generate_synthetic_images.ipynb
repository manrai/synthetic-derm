{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your own images -- which you want to make synthetic versions of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "multiple exception types must be parenthesized (mc_bin_client.py, line 278)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/synthetic-derm/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3577\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn[6], line 24\u001b[0m\n    from tap import Tap\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m~/synthetic-derm/.venv/lib/python3.10/site-packages/tap.py:6\u001b[0;36m\n\u001b[0;31m    from mc_bin_client import mc_bin_client, memcacheConstants as Constants\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m~/synthetic-derm/.venv/lib/python3.10/site-packages/mc_bin_client/mc_bin_client.py:278\u001b[0;36m\u001b[0m\n\u001b[0;31m    except MemcachedError, e:\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m multiple exception types must be parenthesized\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "import math\n",
    "import os\n",
    "import pdb\n",
    "import datetime\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Any, Callable, Iterable, List, Optional, Union, Literal\n",
    "import pandas as pd\n",
    "import diffusers\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from diffusers import StableDiffusionInpaintPipeline, StableDiffusionPipeline, DPMSolverMultistepScheduler\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "from torch import Tensor, autocast\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import functional as TVF\n",
    "from torchvision.utils import make_grid\n",
    "from tqdm.rich import tqdm, trange\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a single batch of synthetic images, and display in this notebook using the Grid format that Luke designed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the following script to generate lots of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this notebook, generate about 100 synthetic images from a dummy dataset (with labels) to demonstrate how it works. There should be streamlined functionality to do this (just choose method, backbone, etc.) \n",
    "\n",
    "# generate_synthetic_dataset(\n",
    "# real_images, # needs to be a metadata dataframe -- containing where to find an image, the label, etc.\n",
    "# map_real_to_synthetic_label,  (this would be the hash for fitz, or some kind of unique ID which we need to store)\n",
    "# method = \"text-to-image\", \"inpaint\", \"outpaint\",\n",
    "# text_label, (for text-to-image, this is the image description \"label\")\n",
    "# text_prompt,   # the prompt that will be applied to the label -- this is optional\n",
    "# num_synthetic_per_real,  (defaults to 10)\n",
    "# num_total, # option for specifying the total dataset size we want -- we will handle dataset balance\n",
    "# num_total_type, # options are balanced, same --  works with num_total, do we want to make a balanced dataset or keep the same proportions\n",
    "# output_dir,\n",
    "# fine_tune, (true or false), whether to fine-tune the model initially\n",
    "# backbone = \"StableDiffusion...\"\n",
    "# )\n",
    "\n",
    "# Then, we can show how to run the script for generating larger amounts of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python generate.py --output_root generations-pretrained --instance_data_dir=${FITZPATRICK17K_DATASET_DIR} --model_type \"text-to-image\" --pretrained_model_name_or_path=\"stabilityai/stable-diffusion-2-1-base\" --instance_prompt=\"An image of {}, a skin disease\" --disease_class=allergic-contact-dermatitis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
