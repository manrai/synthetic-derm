{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Dermatology Image Classifier with Synthetic Data\n",
    "\n",
    "This notebook demonstrates how to train an image classifier for dermatological conditions using both real and synthetic images. We'll explore how synthetic data can improve model performance, especially in scenarios with limited real training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Imports\n",
    "First, let's import all necessary libraries:\n",
    "\n",
    "Use `pip install -e .` to install the synderm package "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synderm.splits.train_test_splitter import synthetic_train_val_split\n",
    "from statsmodels.stats.proportion import proportion_confint\n",
    "from datasets import load_dataset, Image\n",
    "import pandas as pd\n",
    "import torch\n",
    "from fastai.vision.all import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import wandb\n",
    "from fastai.callback.wandb import *\n",
    "from statsmodels.stats.proportion import proportion_confint\n",
    "from itertools import product\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Loading and Preparation\n",
    "\n",
    "We'll use the Fitzpatrick17k dataset, focusing on the top 9 most common skin conditions:\n",
    "\n",
    "We will:\n",
    "1. Load training data from Fitzpatrick17k dataset\n",
    "2. Select the top 9 most frequent skin conditions\n",
    "3. Set up proper file paths\n",
    "4. Verify train/test set separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/test mutually exclusive.\n"
     ]
    }
   ],
   "source": [
    "# Set image directory and fastai path\n",
    "image_dir = \"/n/data1/hms/dbmi/manrai/derm/\"\n",
    "path = Path(image_dir)\n",
    "\n",
    "# Set the generation folder, this is where images are stored\n",
    "generation_folder = \"all_generations/finetune-inpaint/\"\n",
    "generation_type = \"inpaint\"\n",
    "\n",
    "# Load in the training data\n",
    "metadata_train = pd.read_csv(\"/n/data1/hms/dbmi/manrai/derm/Fitzpatrick17k/fitzpatrick17k_10label_clean_training.csv\")\n",
    "top_n_labels = metadata_train[\"label\"].value_counts().index[:9]\n",
    "metadata_train = metadata_train[metadata_train[\"label\"].isin(top_n_labels)].reset_index(drop=True)\n",
    "metadata_train['location'] = 'Fitzpatrick17k/finalfitz17k/' + metadata_train['md5hash'] + '.jpg'\n",
    "metadata_train[\"synthetic\"] = False\n",
    "\n",
    "# Load in testing data\n",
    "test_data = pd.read_csv(\"/n/data1/hms/dbmi/manrai/derm/Fitzpatrick17k/fitzpatrick17k_10label_clean_held_out_set.csv\")\n",
    "test_data = test_data[test_data[\"label\"].isin(top_n_labels)].reset_index(drop=True)\n",
    "test_data['location'] = 'Fitzpatrick17k/finalfitz17k/' + test_data['md5hash'] + '.jpg'\n",
    "test_data['synthetic'] = False\n",
    "test_data['is_valid'] = False\n",
    "\n",
    "ids_train = set(metadata_train[\"md5hash\"])\n",
    "ids_test = set(test_data[\"md5hash\"])\n",
    "\n",
    "if ids_train.isdisjoint(ids_test):\n",
    "    print(\"train/test mutually exclusive.\")\n",
    "else:\n",
    "    print(\"train/test not mutually exclusive.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Experiment Parameters\n",
    "\n",
    "Define key parameters for our experiment:\n",
    "- `per_class_test_size`: Number of test images per class (40)\n",
    "- `n_real_per_class`: Number of real training images per class (32)\n",
    "- `n_synthetic_per_real`: Number of synthetic images generated per real image (10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters \n",
    "per_class_test_size = 40\n",
    "n_real_per_class = 32\n",
    "n_synthetic_per_real = 10\n",
    "random_state = 111108"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Synthetic Data Generation\n",
    "\n",
    "Create our synthetic dataset by:\n",
    "1. Duplicating the real dataset\n",
    "2. Assigning unique identifiers\n",
    "3. Defining the paths to the synthetic images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, the dataset is duplicated n_synthetic_per_real times\n",
    "df_synthetic = pd.concat([metadata_train]*n_synthetic_per_real, ignore_index=True)\n",
    "\n",
    "# create a variable that represents the nth copy of the image\n",
    "df_synthetic['n'] = df_synthetic.groupby('md5hash').cumcount()\n",
    "df_synthetic['location'] = generation_folder + df_synthetic['label'].str.replace(' ', '-')  + '/' + generation_type +'/0' + df_synthetic['n'].astype(str) + '/' + df_synthetic['md5hash'] + '.png'\n",
    "df_synthetic['synthetic'] = True\n",
    "df_synthetic['Qc'] = ''\n",
    "\n",
    "# drop the 'n' column\n",
    "df_synthetic = df_synthetic.drop(columns=['n'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Model Training with Synthetic Data\n",
    "\n",
    "Now we'll train our first model using both real and synthetic images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = synthetic_train_val_split(\n",
    "    real_data = metadata_train, \n",
    "    synthetic_data = df_synthetic, \n",
    "    per_class_test_size = per_class_test_size,\n",
    "    n_real_per_class = n_real_per_class,\n",
    "    random_state = random_state,\n",
    "    class_column = \"label\",\n",
    "    mapping_real_to_synthetic = \"md5hash\"\n",
    "    )\n",
    "\n",
    "# Add 'is_valid' column\n",
    "train['is_valid'] = False\n",
    "val['is_valid'] = True\n",
    "\n",
    "df = pd.concat([train, val]).reset_index(drop=True)\n",
    "\n",
    "# adjust batch size based on number of images\n",
    "if (len(df[df.is_valid == False])/10 >= 100):\n",
    "    batch_size = 64\n",
    "elif (len(df[df.is_valid == False])/10 >= 10):\n",
    "    batch_size = 32\n",
    "else:\n",
    "    batch_size = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model uses:\n",
    "- EfficientNetV2-M architecture\n",
    "- Early stopping to prevent overfitting\n",
    "- Dynamic batch sizing based on dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thb286/synthetic-derm/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/thb286/synthetic-derm/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_V2_M_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_V2_M_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.959998</td>\n",
       "      <td>2.758843</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>00:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.182790</td>\n",
       "      <td>2.900020</td>\n",
       "      <td>0.705556</td>\n",
       "      <td>0.294444</td>\n",
       "      <td>00:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.739314</td>\n",
       "      <td>3.136784</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>00:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.518641</td>\n",
       "      <td>3.127845</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>00:54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement since epoch 0: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Create a fastai dataloader\n",
    "dls = ImageDataLoaders.from_df(df, \n",
    "                        path,\n",
    "                        fn_col='location',\n",
    "                        label_col='label',\n",
    "                        valid_col='is_valid', \n",
    "                        bs=64,\n",
    "                        item_tfms=Resize(224),\n",
    "                        batch_tfms=[])            \n",
    "\n",
    "# Create the learner\n",
    "learn = vision_learner(\n",
    "    dls,\n",
    "    arch=efficientnet_v2_m,\n",
    "    metrics=[error_rate, accuracy]\n",
    ")\n",
    "\n",
    "# Fit without wandb callback\n",
    "learn.fit(10, cbs=[EarlyStoppingCallback(monitor='valid_loss', min_delta=0.0, patience=3)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Model Evaluation (with Synthetic Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model including synthetic images: \n",
      "Top-1 Accuracy: 0.24166666666666667\n",
      "Top-1 95% CI: 0.19744498136010485 - 0.2858883519732285\n",
      "Top-3 Accuracy: 0.5277777777777778\n",
      "Top-3 95% CI: 0.47620795950042477 - 0.5793475960551309\n"
     ]
    }
   ],
   "source": [
    "# Predict on test data\n",
    "test_dl = dls.test_dl(test_data)\n",
    "\n",
    "# Get predictions and probabilities for test set\n",
    "preds, _ = learn.get_preds(dl=test_dl)\n",
    "\n",
    "# Get top-3 probabilities and labels\n",
    "top3_prob, top3_label = torch.topk(preds, k=3, dim=1)\n",
    "\n",
    "# Convert top3_label indices to class labels\n",
    "top3_label = [[learn.dls.vocab[idx] for idx in indices] for indices in top3_label]\n",
    "\n",
    "# Get true labels for test set\n",
    "true_labels = test_data['label'].reset_index(drop=True)\n",
    "\n",
    "# Calculate top-1 accuracy\n",
    "top1_label = [labels[0] for labels in top3_label]\n",
    "top1_acc = np.mean(np.array(top1_label) == np.array(true_labels))\n",
    "\n",
    "# Calculate top-3 accuracy\n",
    "top3_acc = np.mean([\n",
    "    true_labels.iloc[i] in top3_label[i]\n",
    "    for i in range(len(true_labels))\n",
    "])\n",
    "\n",
    "top1_ci_lower, top1_ci_upper = proportion_confint(\n",
    "    count=top1_acc * len(true_labels),\n",
    "    nobs=len(true_labels),\n",
    "    alpha=0.05,\n",
    "    method='normal'\n",
    ")\n",
    "top3_ci_lower, top3_ci_upper = proportion_confint(\n",
    "    count=top3_acc * len(true_labels),\n",
    "    nobs=len(true_labels),\n",
    "    alpha=0.05,\n",
    "    method='normal'\n",
    ")\n",
    "\n",
    "# Print accuracy scores\n",
    "print(\"Accuracy of the model including synthetic images: \")\n",
    "print(f'Top-1 Accuracy: {top1_acc}')\n",
    "print(f'Top-1 95% CI: {top1_ci_lower} - {top1_ci_upper}')\n",
    "print(f'Top-3 Accuracy: {top3_acc}')\n",
    "print(f'Top-3 95% CI: {top3_ci_lower} - {top3_ci_upper}')\n",
    "\n",
    "# Extract top-1, top-2, and top-3 probabilities\n",
    "top1_prob_arr = top3_prob[:, 0].numpy()\n",
    "top2_prob_arr = top3_prob[:, 1].numpy()\n",
    "top3_prob_arr = top3_prob[:, 2].numpy()\n",
    "\n",
    "# Extract top-1, top-2, and top-3 labels\n",
    "top1_label = [labels[0] for labels in top3_label]\n",
    "top2_label = [labels[1] for labels in top3_label]\n",
    "top3_label = [labels[2] for labels in top3_label]\n",
    "\n",
    "# Get md5hashes\n",
    "md5hashes = test_data['md5hash'].reset_index(drop=True)\n",
    "\n",
    "# Create dataframe of predictions\n",
    "df_pred = pd.DataFrame({\n",
    "    'architecture': \"EfficientNet-V2-M\",\n",
    "    'random_state': random_state,\n",
    "    'augmentation': \"None\",\n",
    "    'gen_folder': generation_folder,\n",
    "    'generation_type': generation_type,\n",
    "    'n_training_per_label': n_real_per_class,\n",
    "    'n_synthetic_per_real': n_synthetic_per_real,\n",
    "    'include_synthetic': True,\n",
    "    'md5hash': md5hashes,\n",
    "    'true_label': true_labels,\n",
    "    'top1_label': top1_label,\n",
    "    'top1_prob': top1_prob_arr,\n",
    "    'top2_label': top2_label,\n",
    "    'top2_prob': top2_prob_arr,\n",
    "    'top3_label': top3_label,\n",
    "    'top3_prob': top3_prob_arr\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Baseline Model (No Synthetic Data)\n",
    "\n",
    "For comparison, we'll train and evaluate a model using only the real images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ns, val_ns = synthetic_train_val_split(\n",
    "    real_data = metadata_train, \n",
    "    synthetic_data = None, \n",
    "    per_class_test_size = per_class_test_size,\n",
    "    n_real_per_class = n_real_per_class,\n",
    "    random_state = random_state,\n",
    "    class_column = \"label\",\n",
    "    mapping_real_to_synthetic = \"md5hash\"\n",
    "    )\n",
    "\n",
    "# Add 'is_valid' column\n",
    "train_ns['is_valid'] = False\n",
    "val_ns['is_valid'] = True\n",
    "\n",
    "df_ns = pd.concat([train_ns, val_ns]).reset_index(drop=True)\n",
    "\n",
    "# adjust batch size based on number of images\n",
    "if (len(df_ns[df_ns.is_valid == False])/10 >= 100):\n",
    "    batch_size = 64\n",
    "elif (len(df_ns[df_ns.is_valid == False])/10 >= 10):\n",
    "    batch_size = 32\n",
    "else:\n",
    "    batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thb286/synthetic-derm/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/thb286/synthetic-derm/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_V2_M_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_V2_M_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.826281</td>\n",
       "      <td>2.661138</td>\n",
       "      <td>0.827778</td>\n",
       "      <td>0.172222</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.263444</td>\n",
       "      <td>2.559533</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.932132</td>\n",
       "      <td>2.562016</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.645862</td>\n",
       "      <td>2.635431</td>\n",
       "      <td>0.797222</td>\n",
       "      <td>0.202778</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.453256</td>\n",
       "      <td>2.700307</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement since epoch 1: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Create a fastai dataloader\n",
    "dls_ns = ImageDataLoaders.from_df(df_ns, \n",
    "                        path,\n",
    "                        fn_col='location',\n",
    "                        label_col='label',\n",
    "                        valid_col='is_valid', \n",
    "                        bs=64,\n",
    "                        item_tfms=Resize(224),\n",
    "                        batch_tfms=[])            \n",
    "\n",
    "# Create the learner\n",
    "learn = vision_learner(\n",
    "    dls_ns,\n",
    "    arch=efficientnet_v2_m,\n",
    "    metrics=[error_rate, accuracy]\n",
    ")\n",
    "\n",
    "# Fit without wandb callback\n",
    "learn.fit(10, cbs=[EarlyStoppingCallback(monitor='valid_loss', min_delta=0.0, patience=3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/6 00:00&lt;?]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model (no synthetic images): \n",
      "Top-1 Accuracy: 0.18888888888888888\n",
      "Top-1 95% CI: 0.14845549263775715 - 0.22932228514002062\n",
      "Top-3 Accuracy: 0.49166666666666664\n",
      "Top-3 95% CI: 0.4400242546931338 - 0.5433090786401995\n"
     ]
    }
   ],
   "source": [
    "# Predict on test data\n",
    "test_dl = dls.test_dl(test_data)\n",
    "\n",
    "# Get predictions and probabilities for test set\n",
    "preds, _ = learn.get_preds(dl=test_dl)\n",
    "\n",
    "# Get top-3 probabilities and labels\n",
    "top3_prob, top3_label = torch.topk(preds, k=3, dim=1)\n",
    "\n",
    "# Convert top3_label indices to class labels\n",
    "top3_label = [[learn.dls.vocab[idx] for idx in indices] for indices in top3_label]\n",
    "\n",
    "# Get true labels for test set\n",
    "true_labels = test_data['label'].reset_index(drop=True)\n",
    "\n",
    "# Calculate top-1 accuracy\n",
    "top1_label = [labels[0] for labels in top3_label]\n",
    "top1_acc = np.mean(np.array(top1_label) == np.array(true_labels))\n",
    "\n",
    "# Calculate top-3 accuracy\n",
    "top3_acc = np.mean([\n",
    "    true_labels.iloc[i] in top3_label[i]\n",
    "    for i in range(len(true_labels))\n",
    "])\n",
    "\n",
    "top1_ci_lower, top1_ci_upper = proportion_confint(\n",
    "    count=top1_acc * len(true_labels),\n",
    "    nobs=len(true_labels),\n",
    "    alpha=0.05,\n",
    "    method='normal'\n",
    ")\n",
    "top3_ci_lower, top3_ci_upper = proportion_confint(\n",
    "    count=top3_acc * len(true_labels),\n",
    "    nobs=len(true_labels),\n",
    "    alpha=0.05,\n",
    "    method='normal'\n",
    ")\n",
    "\n",
    "# Print accuracy scores\n",
    "print(\"Accuracy of the model (no synthetic images): \")\n",
    "print(f'Top-1 Accuracy: {top1_acc}')\n",
    "print(f'Top-1 95% CI: {top1_ci_lower} - {top1_ci_upper}')\n",
    "print(f'Top-3 Accuracy: {top3_acc}')\n",
    "print(f'Top-3 95% CI: {top3_ci_lower} - {top3_ci_upper}')\n",
    "\n",
    "# Extract top-1, top-2, and top-3 probabilities\n",
    "top1_prob_arr = top3_prob[:, 0].numpy()\n",
    "top2_prob_arr = top3_prob[:, 1].numpy()\n",
    "top3_prob_arr = top3_prob[:, 2].numpy()\n",
    "\n",
    "# Extract top-1, top-2, and top-3 labels\n",
    "top1_label = [labels[0] for labels in top3_label]\n",
    "top2_label = [labels[1] for labels in top3_label]\n",
    "top3_label = [labels[2] for labels in top3_label]\n",
    "\n",
    "# Get md5hashes\n",
    "md5hashes = test_data['md5hash'].reset_index(drop=True)\n",
    "\n",
    "# Create dataframe of predictions\n",
    "df_pred = pd.DataFrame({\n",
    "    'architecture': \"EfficientNet-V2-M\",\n",
    "    'random_state': random_state,\n",
    "    'augmentation': \"None\",\n",
    "    'gen_folder': generation_folder,\n",
    "    'generation_type': generation_type,\n",
    "    'n_training_per_label': n_real_per_class,\n",
    "    'n_synthetic_per_real': n_synthetic_per_real,\n",
    "    'include_synthetic': True,\n",
    "    'md5hash': md5hashes,\n",
    "    'true_label': true_labels,\n",
    "    'top1_label': top1_label,\n",
    "    'top1_prob': top1_prob_arr,\n",
    "    'top2_label': top2_label,\n",
    "    'top2_prob': top2_prob_arr,\n",
    "    'top3_label': top3_label,\n",
    "    'top3_prob': top3_prob_arr\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the complete experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The entire experiment can be run using this script, although this will take a while to run\n",
    "!python skin_classification_with_augmentation.py \\    \n",
    "    --dataset hugginface_repo \\ \n",
    "    --n_real_per_label_list \"[1, 8, 16, 32, 64, 128, 228]\" \\\n",
    "    --max_batch_size 32 \\\n",
    "    --arg2 value2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
