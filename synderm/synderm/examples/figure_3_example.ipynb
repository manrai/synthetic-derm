{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from fastai.vision.all import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import wandb\n",
    "from fastai.callback.wandb import *\n",
    "from statsmodels.stats.proportion import proportion_confint\n",
    "from itertools import product\n",
    "import os\n",
    "\n",
    "from datasets import load_dataset, Image\n",
    "from synderm.splits.train_test_splitter import synthetic_train_val_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: get rid of wandb logging\n",
    "# TODO: create the huggingface dataset\n",
    "# TODO: complete this demo, using the huggingface dataset and with some kind of visualization at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets\n",
    "synthetic_derm = \"lukemelas/synthetic-derm\"  # 440 total images in each class using all_generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/test mutually exclusive.\n"
     ]
    }
   ],
   "source": [
    "# Load in the labels we are using for training data\n",
    "metadata_train = pd.read_csv(\"/n/data1/hms/dbmi/manrai/derm/Fitzpatrick17k/fitzpatrick17k_10label_clean_training.csv\")\n",
    "top_n_labels = metadata_train[\"label\"].value_counts().index[:9]\n",
    "metadata_train = metadata_train[metadata_train[\"label\"].isin(top_n_labels)].reset_index(drop=True)\n",
    "metadata_train['location'] = 'Fitzpatrick17k/finalfitz17k/' + metadata_train['md5hash'] + '.jpg'\n",
    "metadata_train[\"synthetic\"] = False\n",
    "\n",
    "# These are the labels we are using for testing\n",
    "test_data = pd.read_csv(\"/n/data1/hms/dbmi/manrai/derm/Fitzpatrick17k/fitzpatrick17k_10label_clean_held_out_set.csv\")\n",
    "test_data = test_data[test_data[\"label\"].isin(top_n_labels)].reset_index(drop=True)\n",
    "test_data['location'] = 'Fitzpatrick17k/finalfitz17k/' + test_data['md5hash'] + '.jpg'\n",
    "test_data['synthetic'] = False\n",
    "test_data['is_valid'] = False\n",
    "\n",
    "ids_train = set(metadata_train[\"md5hash\"])\n",
    "ids_test = set(test_data[\"md5hash\"])\n",
    "\n",
    "if ids_train.isdisjoint(ids_test):\n",
    "    print(\"train/test mutually exclusive.\")\n",
    "else:\n",
    "    print(\"train/test not mutually exclusive.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model with 32 real training images per disease condition, including synthetic data\n",
    "\n",
    "We will train a model with 32 real images per class, with and without synthetic images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set image directory and fastai path\n",
    "image_dir = \"/n/data1/hms/dbmi/manrai/derm/\"\n",
    "path = Path(image_dir)\n",
    "\n",
    "# Set the generation folder -- using the finetuned model\n",
    "generation_folder = \"all_generations/finetune-inpaint/\"\n",
    "generation_type = \"inpaint\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters \n",
    "per_class_test_size = 40\n",
    "n_real_per_class = 32\n",
    "n_synthetic_per_real = 10\n",
    "\n",
    "random_state = 111108\n",
    "wandb_project = \"n_real_per_disease_x\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, the dataset is duplicated n_synthetic_per_real times\n",
    "df_synthetic = pd.concat([metadata_train]*n_synthetic_per_real, ignore_index=True)\n",
    "\n",
    "# create a variable that represents the nth copy of the image\n",
    "df_synthetic['n'] = df_synthetic.groupby('md5hash').cumcount()\n",
    "df_synthetic['location'] = generation_folder + df_synthetic['label'].str.replace(' ', '-')  + '/' + generation_type +'/0' + df_synthetic['n'].astype(str) + '/' + df_synthetic['md5hash'] + '.png'\n",
    "df_synthetic['synthetic'] = True\n",
    "df_synthetic['Qc'] = ''\n",
    "\n",
    "# drop the 'n' column\n",
    "df_synthetic = df_synthetic.drop(columns=['n'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = synthetic_train_val_split(\n",
    "    real_data = metadata_train, \n",
    "    synthetic_data = df_synthetic, \n",
    "    per_class_test_size = per_class_test_size,\n",
    "    n_real_per_class = n_real_per_class,\n",
    "    random_state = random_state,\n",
    "    class_column = \"label\",\n",
    "    mapping_real_to_synthetic = \"md5hash\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 'is_valid' column\n",
    "train['is_valid'] = False\n",
    "val['is_valid'] = True\n",
    "\n",
    "df = pd.concat([train, val]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a fastai dataloader\n",
    "dls = ImageDataLoaders.from_df(df, \n",
    "                        path,\n",
    "                        fn_col='location',\n",
    "                        label_col='label',\n",
    "                        valid_col='is_valid', \n",
    "                        bs=batch_size,\n",
    "                        item_tfms=Resize(224),\n",
    "                        batch_tfms=[])            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtbu\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/thb286/synthetic-derm/wandb/run-20241110_191711-a730uild</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tbu/n_real_per_disease_x/runs/a730uild' target=\"_blank\">mild-silence-5</a></strong> to <a href='https://wandb.ai/tbu/n_real_per_disease_x' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tbu/n_real_per_disease_x' target=\"_blank\">https://wandb.ai/tbu/n_real_per_disease_x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tbu/n_real_per_disease_x/runs/a730uild' target=\"_blank\">https://wandb.ai/tbu/n_real_per_disease_x/runs/a730uild</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/tbu/n_real_per_disease_x/runs/a730uild?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f8be830b130>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set config parameters for wandb\n",
    "config = dict (\n",
    "    architecture = \"EfficientNet-V2-M\",\n",
    "    gen_folder = generation_folder,\n",
    "    random_state = random_state,\n",
    "    augmentation = \"None\", \n",
    "    n_training_per_label = n_real_per_class,\n",
    "    include_synthetic = True,\n",
    "    n_synthetic_per_real = n_synthetic_per_real,\n",
    "    generation_type = generation_type\n",
    ")\n",
    "\n",
    "# set tags for wandb and\n",
    "sample_tag = \"n_real_per_label_\" + str(n_real_per_class)\n",
    "seed_tag = \"seed_\" + str(random_state)\n",
    "include_synthetic_tag = \"include_synthetic_\" + str(True)\n",
    "generation_type_tag = str(generation_type)\n",
    "\n",
    "wandb.init(\n",
    "    project=wandb_project,\n",
    "    tags=[sample_tag, seed_tag, include_synthetic_tag, generation_type_tag],\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thb286/synthetic-derm/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/thb286/synthetic-derm/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_V2_M_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_V2_M_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "learn = vision_learner(dls, \n",
    "                    arch=efficientnet_v2_m,\n",
    "                    metrics=[error_rate, accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.915981</td>\n",
       "      <td>2.912237</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>00:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.180606</td>\n",
       "      <td>2.913154</td>\n",
       "      <td>0.730556</td>\n",
       "      <td>0.269444</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.756596</td>\n",
       "      <td>3.069446</td>\n",
       "      <td>0.738889</td>\n",
       "      <td>0.261111</td>\n",
       "      <td>01:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.530889</td>\n",
       "      <td>3.091721</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>01:50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement since epoch 0: early stopping\n"
     ]
    }
   ],
   "source": [
    "# fit with wandb callback\n",
    "learn.fit(10, cbs=[WandbCallback(), EarlyStoppingCallback (monitor='valid_loss', min_delta=0.0, patience=3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/6 00:00&lt;?]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>█▅▁█</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>eps_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eps_1</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>error_rate</td><td>▁▄█▁</td></tr><tr><td>lr_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr_1</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mom_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mom_1</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>raw_loss</td><td>█▆▅▄▆▃▅▄▅▃▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▂▂▁▁▁▁▁▂▁▂▂▁▁▁</td></tr><tr><td>sqr_mom_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>sqr_mom_1</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>top1_acc</td><td>▁</td></tr><tr><td>top1_ci_lower</td><td>▁</td></tr><tr><td>top1_ci_upper</td><td>▁</td></tr><tr><td>top3_acc</td><td>▁</td></tr><tr><td>top3_ci_lower</td><td>▁</td></tr><tr><td>top3_ci_upper</td><td>▁</td></tr><tr><td>train_loss</td><td>█▇▇▆▆▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_samples_per_sec</td><td>█▆█▇██▇▇▆█▇▅▅▆▇▇▇▇▇██▇▆▆▇▆▅▄▁▄▅▅▆▆▄▄▄▆▅▆</td></tr><tr><td>valid_loss</td><td>▁▁▇█</td></tr><tr><td>wd_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>wd_1</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.275</td></tr><tr><td>epoch</td><td>4</td></tr><tr><td>eps_0</td><td>1e-05</td></tr><tr><td>eps_1</td><td>1e-05</td></tr><tr><td>error_rate</td><td>0.725</td></tr><tr><td>lr_0</td><td>0.001</td></tr><tr><td>lr_1</td><td>0.001</td></tr><tr><td>mom_0</td><td>0.9</td></tr><tr><td>mom_1</td><td>0.9</td></tr><tr><td>raw_loss</td><td>0.30807</td></tr><tr><td>sqr_mom_0</td><td>0.99</td></tr><tr><td>sqr_mom_1</td><td>0.99</td></tr><tr><td>top1_acc</td><td>0.22222</td></tr><tr><td>top1_ci_lower</td><td>0.17928</td></tr><tr><td>top1_ci_upper</td><td>0.26517</td></tr><tr><td>top3_acc</td><td>0.52222</td></tr><tr><td>top3_ci_lower</td><td>0.47062</td></tr><tr><td>top3_ci_upper</td><td>0.57382</td></tr><tr><td>train_loss</td><td>0.53089</td></tr><tr><td>train_samples_per_sec</td><td>155.01752</td></tr><tr><td>valid_loss</td><td>3.09172</td></tr><tr><td>wd_0</td><td>0.01</td></tr><tr><td>wd_1</td><td>0.01</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">mild-silence-5</strong> at: <a href='https://wandb.ai/tbu/n_real_per_disease_x/runs/a730uild' target=\"_blank\">https://wandb.ai/tbu/n_real_per_disease_x/runs/a730uild</a><br/> View project at: <a href='https://wandb.ai/tbu/n_real_per_disease_x' target=\"_blank\">https://wandb.ai/tbu/n_real_per_disease_x</a><br/>Synced 5 W&B file(s), 0 media file(s), 40 artifact file(s) and 2 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241110_191711-a730uild/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predict on test data\n",
    "test_dl = dls.test_dl(test_data)\n",
    "\n",
    "# get predictions and probabilities for test set\n",
    "preds, _ = learn.get_preds(dl=test_dl)\n",
    "\n",
    "# get predicted labels for top-1 and top-3\n",
    "top1_pred = torch.argmax(preds, dim=1)\n",
    "top3_pred = torch.topk(preds, k=3, dim=1).indices\n",
    "\n",
    "md5hashes = test_data['md5hash']\n",
    "\n",
    "# get predicted labels and probabilities for top-1 and top-3\n",
    "top1_prob, top1_label = torch.topk(preds, k=1, dim=1)\n",
    "top3_prob, top3_label = torch.topk(preds, k=3, dim=1)\n",
    "\n",
    "# convert tensor labels to class labels\n",
    "top1_label = [learn.dls.vocab[i] for i in top1_label.squeeze()]\n",
    "top3_label = [[learn.dls.vocab[j] for j in i] for i in top3_label]\n",
    "\n",
    "# get true labels for test set\n",
    "true_labels = test_data['label']\n",
    "\n",
    "# calculate accuracy scores\n",
    "top1_acc = (top1_label == true_labels).mean()\n",
    "top3_acc = torch.zeros(len(true_labels))\n",
    "for i in range(len(true_labels)):\n",
    "    top3_acc[i] = true_labels[i] in top3_label[i]\n",
    "top3_acc = top3_acc.mean()\n",
    "\n",
    "# calculate upper and lower bounds for 95% confidence interval\n",
    "top1_ci_lower, top1_ci_upper = proportion_confint(top1_acc*len(true_labels), len(true_labels), alpha=0.05, method='normal')\n",
    "top3_ci_lower, top3_ci_upper = proportion_confint(top3_acc*len(true_labels), len(true_labels), alpha=0.05, method='normal')\n",
    "\n",
    "# log accuracy scores to wandb\n",
    "wandb.log({'top1_acc': top1_acc,\n",
    "            'top1_ci_lower': top1_ci_lower,\n",
    "            'top1_ci_upper': top1_ci_upper,\n",
    "            'top3_acc': top3_acc,\n",
    "            'top3_ci_lower': top3_ci_lower,\n",
    "            'top3_ci_upper': top3_ci_upper})\n",
    "\n",
    "# split up the top3 probabilities\n",
    "top1_prob, top2_prob, top3_prob = torch.split(top3_prob, 1, dim=1)\n",
    "\n",
    "# Convert the tensors to NumPy arrays\n",
    "top1_prob_arr = top1_prob.numpy().flatten()\n",
    "top2_prob_arr = top2_prob.numpy().flatten()\n",
    "top3_prob_arr = top3_prob.numpy().flatten()\n",
    "\n",
    "# split up the top3 labels to match \n",
    "top1_label = [sublist[0] for sublist in top3_label]\n",
    "top2_label = [sublist[1] for sublist in top3_label]\n",
    "top3_label = [sublist[2] for sublist in top3_label]\n",
    "\n",
    "# create dataframe of predictions\n",
    "df_pred = pd.DataFrame({\n",
    "    'architecture' : \"EfficientNet-V2-M\",\n",
    "    'random_state' : random_state,\n",
    "    'augmentation' : \"None\",\n",
    "    'gen_folder' : generation_folder,\n",
    "    'generation_type' : generation_type,\n",
    "    'n_training_per_label' : n_real_per_class,\n",
    "    'n_synthetic_per_real' : n_synthetic_per_real,\n",
    "    'include_synthetic' : True,\n",
    "    'md5hash': md5hashes,\n",
    "    'true_label': true_labels,\n",
    "    'top1_label': top1_label,\n",
    "    'top1_prob': top1_prob_arr,\n",
    "    'top2_label': top2_label,\n",
    "    'top2_prob': top2_prob_arr,\n",
    "    'top3_label': top3_label\n",
    "})\n",
    "\n",
    "# log the test predictions\n",
    "wandb.log({\"test_predictions\": wandb.Table(dataframe=df_pred)})\n",
    "\n",
    "# Finish the run\n",
    "wandb.finish()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model with 32 real training images per disease condition, no synthetic images included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ns, val_ns = synthetic_train_val_split(\n",
    "    real_data = metadata_train, \n",
    "    synthetic_data = None, \n",
    "    per_class_test_size = per_class_test_size,\n",
    "    n_real_per_class = n_real_per_class,\n",
    "    random_state = random_state,\n",
    "    class_column = \"label\",\n",
    "    mapping_real_to_synthetic = \"md5hash\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/thb286/synthetic-derm/wandb/run-20241110_192530-4f5ymuwy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tbu/n_real_per_disease_x/runs/4f5ymuwy' target=\"_blank\">iconic-gorge-6</a></strong> to <a href='https://wandb.ai/tbu/n_real_per_disease_x' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tbu/n_real_per_disease_x' target=\"_blank\">https://wandb.ai/tbu/n_real_per_disease_x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tbu/n_real_per_disease_x/runs/4f5ymuwy' target=\"_blank\">https://wandb.ai/tbu/n_real_per_disease_x/runs/4f5ymuwy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thb286/synthetic-derm/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/thb286/synthetic-derm/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_V2_M_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_V2_M_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.323790</td>\n",
       "      <td>2.822096</td>\n",
       "      <td>0.872222</td>\n",
       "      <td>0.127778</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.003263</td>\n",
       "      <td>2.617331</td>\n",
       "      <td>0.836111</td>\n",
       "      <td>0.163889</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.770729</td>\n",
       "      <td>2.589204</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.177778</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.573370</td>\n",
       "      <td>2.703261</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.402319</td>\n",
       "      <td>2.874825</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.238272</td>\n",
       "      <td>2.926580</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement since epoch 2: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Add 'is_valid' column\n",
    "train_ns['is_valid'] = False\n",
    "val_ns['is_valid'] = True\n",
    "\n",
    "df_ns = pd.concat([train_ns, val_ns]).reset_index(drop=True)\n",
    "\n",
    "# Create a fastai dataloader\n",
    "dls = ImageDataLoaders.from_df(df_ns, \n",
    "                        path,\n",
    "                        fn_col='location',\n",
    "                        label_col='label',\n",
    "                        valid_col='is_valid', \n",
    "                        bs=batch_size,\n",
    "                        item_tfms=Resize(224),\n",
    "                        batch_tfms=[])            \n",
    "\n",
    "# Set config parameters for wandb\n",
    "config = dict (\n",
    "    architecture = \"EfficientNet-V2-M\",\n",
    "    gen_folder = generation_folder,\n",
    "    random_state = random_state,\n",
    "    augmentation = \"None\", \n",
    "    n_training_per_label = n_real_per_class,\n",
    "    include_synthetic = False,\n",
    "    n_synthetic_per_real = n_synthetic_per_real,\n",
    "    generation_type = generation_type\n",
    ")\n",
    "\n",
    "# set tags for wandb and\n",
    "sample_tag = \"n_real_per_label_\" + str(n_real_per_class)\n",
    "seed_tag = \"seed_\" + str(random_state)\n",
    "include_synthetic_tag = \"include_synthetic_\" + str(True)\n",
    "generation_type_tag = str(generation_type)\n",
    "\n",
    "wandb.init(\n",
    "    project=wandb_project,\n",
    "    tags=[sample_tag, seed_tag, include_synthetic_tag, generation_type_tag],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "learn = vision_learner(dls, \n",
    "                    arch=efficientnet_v2_m,\n",
    "                    metrics=[error_rate, accuracy])\n",
    "\n",
    "# fit with wandb callback\n",
    "learn.fit(10, cbs=[WandbCallback(), EarlyStoppingCallback (monitor='valid_loss', min_delta=0.0, patience=3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/6 00:00&lt;?]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "Error",
     "evalue": "You must call wandb.init() before wandb.log()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m top3_ci_lower, top3_ci_upper \u001b[38;5;241m=\u001b[39m proportion_confint(top3_acc\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(true_labels), \u001b[38;5;28mlen\u001b[39m(true_labels), alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnormal\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# log accuracy scores to wandb\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtop1_acc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop1_acc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtop1_ci_lower\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop1_ci_lower\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtop1_ci_upper\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop1_ci_upper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtop3_acc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop3_acc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtop3_ci_lower\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop3_ci_lower\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtop3_ci_upper\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop3_ci_upper\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# split up the top3 probabilities\u001b[39;00m\n\u001b[1;32m     44\u001b[0m top1_prob, top2_prob, top3_prob \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msplit(top3_prob, \u001b[38;5;241m1\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/synthetic-derm/.venv/lib/python3.10/site-packages/wandb/sdk/lib/preinit.py:36\u001b[0m, in \u001b[0;36mPreInitCallable.<locals>.preinit_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreinit_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m wandb\u001b[38;5;241m.\u001b[39mError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must call wandb.init() before \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mError\u001b[0m: You must call wandb.init() before wandb.log()"
     ]
    }
   ],
   "source": [
    "# predict on test data\n",
    "test_dl = dls.test_dl(test_data)\n",
    "\n",
    "# get predictions and probabilities for test set\n",
    "preds, _ = learn.get_preds(dl=test_dl)\n",
    "\n",
    "# get predicted labels for top-1 and top-3\n",
    "top1_pred = torch.argmax(preds, dim=1)\n",
    "top3_pred = torch.topk(preds, k=3, dim=1).indices\n",
    "\n",
    "md5hashes = test_data['md5hash']\n",
    "\n",
    "# get predicted labels and probabilities for top-1 and top-3\n",
    "top1_prob, top1_label = torch.topk(preds, k=1, dim=1)\n",
    "top3_prob, top3_label = torch.topk(preds, k=3, dim=1)\n",
    "\n",
    "# convert tensor labels to class labels\n",
    "top1_label = [learn.dls.vocab[i] for i in top1_label.squeeze()]\n",
    "top3_label = [[learn.dls.vocab[j] for j in i] for i in top3_label]\n",
    "\n",
    "# get true labels for test set\n",
    "true_labels = test_data['label']\n",
    "\n",
    "# calculate accuracy scores\n",
    "top1_acc = (top1_label == true_labels).mean()\n",
    "top3_acc = torch.zeros(len(true_labels))\n",
    "for i in range(len(true_labels)):\n",
    "    top3_acc[i] = true_labels[i] in top3_label[i]\n",
    "top3_acc = top3_acc.mean()\n",
    "\n",
    "# calculate upper and lower bounds for 95% confidence interval\n",
    "top1_ci_lower, top1_ci_upper = proportion_confint(top1_acc*len(true_labels), len(true_labels), alpha=0.05, method='normal')\n",
    "top3_ci_lower, top3_ci_upper = proportion_confint(top3_acc*len(true_labels), len(true_labels), alpha=0.05, method='normal')\n",
    "\n",
    "# log accuracy scores to wandb\n",
    "wandb.log({'top1_acc': top1_acc,\n",
    "            'top1_ci_lower': top1_ci_lower,\n",
    "            'top1_ci_upper': top1_ci_upper,\n",
    "            'top3_acc': top3_acc,\n",
    "            'top3_ci_lower': top3_ci_lower,\n",
    "            'top3_ci_upper': top3_ci_upper})\n",
    "\n",
    "# split up the top3 probabilities\n",
    "top1_prob, top2_prob, top3_prob = torch.split(top3_prob, 1, dim=1)\n",
    "\n",
    "# Convert the tensors to NumPy arrays\n",
    "top1_prob_arr = top1_prob.numpy().flatten()\n",
    "top2_prob_arr = top2_prob.numpy().flatten()\n",
    "top3_prob_arr = top3_prob.numpy().flatten()\n",
    "\n",
    "# split up the top3 labels to match \n",
    "top1_label = [sublist[0] for sublist in top3_label]\n",
    "top2_label = [sublist[1] for sublist in top3_label]\n",
    "top3_label = [sublist[2] for sublist in top3_label]\n",
    "\n",
    "# create dataframe of predictions\n",
    "df_pred = pd.DataFrame({\n",
    "    'architecture' : \"EfficientNet-V2-M\",\n",
    "    'random_state' : random_state,\n",
    "    'augmentation' : \"None\",\n",
    "    'gen_folder' : generation_folder,\n",
    "    'generation_type' : generation_type,\n",
    "    'n_training_per_label' : n_real_per_class,\n",
    "    'n_synthetic_per_real' : n_synthetic_per_real,\n",
    "    'include_synthetic' : True,\n",
    "    'md5hash': md5hashes,\n",
    "    'true_label': true_labels,\n",
    "    'top1_label': top1_label,\n",
    "    'top1_prob': top1_prob_arr,\n",
    "    'top2_label': top2_label,\n",
    "    'top2_prob': top2_prob_arr,\n",
    "    'top3_label': top3_label\n",
    "})\n",
    "\n",
    "# log the test predictions\n",
    "wandb.log({\"test_predictions\": wandb.Table(dataframe=df_pred)})\n",
    "\n",
    "# Finish the run\n",
    "wandb.finish()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the complete experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The entire experiment can be run using this script, although this will take a while to run\n",
    "!python skin_classification_with_augmentation.py \\    \n",
    "    --dataset hugginface_repo \\ \n",
    "    --n_real_per_label_list \"[1, 8, 16, 32, 64, 128, 228]\" \\\n",
    "    --max_batch_size 32 \\\n",
    "    --arg2 value2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can plot the data from the complete experiment\n",
    "# We can provide the user code to reproduce this, but save the trial data so that user can still plot our results if they are unable to run the model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
